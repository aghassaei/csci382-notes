\documentclass{article}
\input{macros.tex}
\begin{document}

% Cover Page and ToC
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{ \normalsize \textsc{}
		\\ [2.0cm]
		\HRule{1.5pt} \\
		\LARGE \textbf{\uppercase{Algorithms \& Data Structures}
		\HRule{2.0pt} \\ [0.6cm] \LARGE{CSCI 382} \vspace*{10\baselineskip}}
		}
\date{}
\author{\textbf{Erica Blum} \\ 
		2023\\
		Notes by Aliya Ghassaei}

\maketitle
\newpage

\tableofcontents
\newpage

\section{Asymptotic notation}
    \subsection{Definitions}

        \subsubsection{Big-$O$}
            \textbf{Intuition: }If $f(n) \in O(g(n))$ then $f(n)$ grows no faster than $g(n)$. $g$ is an asymptotic upper bound for $f$.
            \begin{definition}
                $O(g(n)) :=  \{f(n) : \exists ~ c, n_0 > 0 ~|~ 0 \leq f(n) \leq c \cdot g(n) \text{ for all } n \geq  n_0 \} $
            \end{definition}

        \subsubsection{Big-$\Omega$}
            \textbf{Intuition: }If  $f(n) \in \Omega(g(n))$, $f(n)$ grows at least as fast as $g(n)$. $f$ is a lower bound on $f$.
            \begin{definition}
                $\Omega(g(n)) := \{f(n) : \exists ~ c,n_0 > 0 ~|~ 0 \leq   c \cdot g(n) \leq f(n) \text{ for all } n \geq n_0\}$
            \end{definition}

        \subsubsection{Big-$\Theta$}
            \textbf{Intuition: }$f(n)$ grows at the same rate/within a constant factor of $g(n)$
            \begin{definition}
                $\Theta(g(n)) := \{ f(n) : \exists ~ c_1, c_2, n_0 > 0 ~|~ 0 \leq c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n) \text{ for all } n \geq  n_0 \}$
            \end{definition}
            \begin{theorem}
                For any two functions $f(n)$ and $g(n)$, $f(n) = \Theta(g(n)) \iff f(n) = O(g(n)) $ and $f(n) = \Omega(g(n))$
            \end{theorem}


        \subsubsection{Little-$o$}
        \begin{definition}
            $o(g(n)) := \{ f(n) : \text{for any }c > 0, \exists ~ n_0 >0 ~|~ 0 \leq f(n) < c \cdot g(n) \text{ for all } n \geq  n_0 \}$
        \end{definition}
        \subsubsection{Little-$\omega$}
        \begin{definition}
            $\omega(g(n)) := \{ f(n) : \text{for any }c > 0, \exists ~ n_0 >0 ~|~ 0 \leq c \cdot g(n) < f(n) \text{ for all } n \geq  n_0 \}$
        \end{definition}
        \begin{theorem}
            $f(n) \in \omega g(n) \iff g(n) \in o(f(n))$
        \end{theorem}

        \subsection{Proofs strategies}
            \subsubsection{Proving from definition}
            This means that you'd use the definition to prove that a function $g$ is in some complexity class.\\
            \textbf{Steps: }
            \begin{enumerate}
                \item 
            \end{enumerate}
            \textbf{Example: }

            \subsubsection{Proving using limit properties}
            Use the following properties:
            \subsubsection{Helpful properties:}
            \textbf{Transitivity: }
            \begin{align*}
                f(n) &= \Theta(g(n)) \tand g(n) = \Theta(h(n)) &\implies f(n) &= \Theta(h(n))\\
                f(n) &= O(g(n)) \tand g(n) = O(h(n)) &\implies f(n) &= O(h(n))\\
                f(n) &= \Omega(g(n)) \tand g(n) = \Omega(h(n)) &\implies f(n) &= \Omega(h(n))\\
                f(n) &= o(g(n))) \tand g(n) = o(h(n)) &\implies f(n) &= o(h(n))\\
                f(n) &= \omega(g(n)) \tand g(n) = \omega(h(n)) &\implies f(n) &= \omega (h(n))
            \end{align*}
            \textbf{Reflexivity: }
            \begin{align*}
                f(n) &= \Theta(f(n))\\
                f(n) &= O(f(n))\\
                f(n) &= \Omega(f(n))
            \end{align*}
            \textbf{Symetry: }
            \begin{align*}
                f(n) = \Theta (g(n)) \iff g(n = \Theta(f(n)))
            \end{align*}
            \textbf{Transpose symetry: }
            \begin{align*}
                f(n) = O(g(n)) \iff g(n) = \Omega(f(n))\\
                f(n) = o(g(n)) \iff g(n) = \omega (f(n))
            \end{align*}

            \textbf{Limit laws: }

            {\centering
            	\begin{tabular}{ll}
            	$\lim_{n\to\infty}f(n)/g(n) \in[0,\infty)$ &	$\Rightarrow f= O(g)$ \\
            	$\lim_{n\to\infty}f(n)/g(n) \in (0,\infty] $ &		$\Rightarrow f= \Omega(g)$ \\
            	$\lim_{n\to\infty}f(n)/g(n) \in (0,\infty)$  &	$\Rightarrow f= \Theta(g)$ \\
            	$\lim_{n\to\infty}f(n)/g(n) = 0$  &	$\Rightarrow f= o(g)$ \\
            	$\lim_{n\to\infty}f(n)/g(n) = \infty$  &	$\Rightarrow f= \omega(g)$
            	\end{tabular}\par
            }
            \textbf{More: }
            \begin{align*}
                f_1 = O(g_1) \tand f_2 = O(g_2) \implies f_1+f_2= O(\max(g_1,g_2))
            \end{align*}

        \subsubsection{Recurrences (substitution, recurrence trees, master theorem)}
        \subsection{Master method}
        Apply Master theorem to solve recurrances of the form $T(n) = aT(n/b) + f(n)$ where $a \geq 1$, $b > 1$, and that $f(n)$ is asymptotically nonnegative.\\
        \textbf{Master Theorem: }
        fix this later
        \begin{theorem}
            
            \textbf{Case 1:} If $f(n) = O(n^{\log_{b}a -\epsilon})$ for some constant $a > 0$, then $T(n) = n \log^b a$.

            \textit{Intuition:} When $f(n)$ is polynomially less than the watershed function, the cost of leaves dominates the cost of the rest of the tree.

            \textbf{Case 2:} If $f(n) = O(n \log^b a \log^k n)$ for some constant $k > 0$, then $T(n) = n \log^b a \log^{k+1} n$.

            \textit{Intuition:} There are $\log n$ levels, each with a cost of $n \log^b a \log kn$.

            \textit{Simple (common) case:} $k = 0 \Rightarrow f(n) = n \log^b a \Rightarrow T(n) = n \log^b a \log n$.

            \textbf{Case 3:} If $f(n) = n \log^b a +$ for some constant $a > 0$, and $f(n)$ satisfies the regularity condition (below), then $T(n) = f(n)$.

            \textit{Regularity condition:} $a f(n/b)^c \leq f(n)$ for some constant $c < 1$ and all large enough $n$. (Usually true for polynomial $f(n)$.)

            \textit{Intuition:} When $f(n)$ is polynomially greater than the watershed $f(n)$, the cost of the root dominates the cost of the leaves.

        \end{theorem}
        \subsection{Recurrence trees}
        If of the form $T(n) = aT(n/b) + f(n)$, the each node has $a$ branches and the starting $a$ branches will be $n/b$. Then next layer will be $n/b^2$ because you are plugging $n/b$ for $n$ in $T(n)$.\\
        The first layer is $f(n)$ time to combine, next layer will be $a/$ the denominator in that branch all times $f(n)$, basically the watershed function when you plug the new $n$ in\\
        keep going till you get $1$. depth = log n base whatever n was divided by. make it into a sum
        
        \begin{enumerate}
            \item given recurrance relation, prove that it's in some class
            \item method: (recurrence tree) -> guess, -> substitution method
            \item look on recurrence sheet 
            \item ref sheet will have mast theorem, properties or relations for exponents and logarithms, summations
        \end{enumerate}
        \subsubsection{Models of computation (comparison model, random access model)}
    \subsection{Solving problems by reducing to searching (choose + apply a data structure)
}


\section{Interfaces \& implementations}

    \textbf{Interfaces:} set, sequence, priority queue\\
    \textbf{Implementations:} arrays, sorted arrays, linked lists, hash tables, BSTs, red-black trees, min/max heap

\subsubsection{Priority queue interface}
\begin{enumerate}
    \item heap
\end{enumerate}
\subsection{Solving problems by reducing to sorting (choose + apply a sorting algorithm)}
\begin{enumerate}
    \item Mergesort
    Insertion sort
    Selection sort
    Heapsort
    
\end{enumerate}
\subsection{Solving problems by designing a new algorithm}
\begin{enumerate}
    \item Brute force
    “Decrease and conquer”
    Divide and conquer
\end{enumerate}


\newpage
\section{Introduction}
    \subsection{Vocabulary}
        \begin{enumerate}
            \item interface: 
            \item implementation
            \item array-based (example: array/list)
            \item static: region of memory stays static
            \item pointer-based (ex: linked list)
            \item dynamic
        \end{enumerate}

\section{Data Structures}

sequence data structute operations in O\\
\begin{tabular}{|c||c|c|c|c|c|}
    \hline
    Implementation & \code{build(X)} & \code{get\_at}/\code{set\_at} & \code{insert\_first}/\code{delete\_first}& insert/delete last & insert at/delete at \\
    \hline
    array & $n$ & 1 & $n$ & $n$ & $n$ \\
    linked list & $n$ & $n$ & 1 &$n$ & $n$ \\
    dynamic array & $n$ & 1 & $n$ & $1_{(a)}$ & $n$ \\
    binary tree & $n \log n$ & $h$ & $h$ & $h$ & $h$ \\

    \hline
\end{tabular}\\
\vspace{.5cm}



Set data structute operations in O\\
\begin{tabular}{|c||c|c|c|c|c|}
    \hline
    Implementation & \code{build(X)} & \code{find(k)} & \code{insert(x)}/\code{delete(x)} & \code{find\_min/max()} & \code{find\_prev/next} \\
    \hline
    array & $n$ & $n$ & $n$ & $n$ & $n$ \\
    Sorted array & $n \log n$ & $n$ & $n$ &1 & $\log n$ \\
    direct access array & $u$ & 1 & $1$ & $u$ & $u$ \\
    Hash table & $n_{(e)}$ & $1_{(e)}$ & $1_{(a)(e)}$ & $n$ & $n$ \\
    binary tree & $n$ & $h$ & $h$ & $h$ & $h$ \\
    \hline
\end{tabular}
    \subsection{Sequences}
        Given a collection of elements called \code{X}, store elements $x_0, \dots, x_{n-1}$
        \subsubsection{Static Operations}
            \begin{enumerate}
                \item \code{build(X)} - builds the sequence from \code{X}
                \item \code{iter\_seq()} output items in order
                \item \code{len()} -  returns the number of elements in \code{X}
                \item \code{get\_at(i)} - returns item at index $i$
                \item \code{set\_at(i, x)} - insert $x$ at location $i$ 
            \end{enumerate}
        \subsubsection{Dynamic Operations}
        Dynamic sequences use static sequence operations in addition to these operations:
            \begin{enumerate}
                \item \code{insert\_at(i, x)} - inserts item $x$ at location $i$
                \item \code{delete\_at(i)} - deletes and returns item at location $i$
            \end{enumerate}
    \subsection{Sets}
        \subsubsection{Static Operations}
            \begin{enumerate}
                \item \code{build(X)} - builds set
                    \subitem - with array implementation, \code{build(X)} $\in O(n)$ where $n = |X|$
                \item \code{len()} - returns $|X|$
                \item \code{find(k)} - returns item with key $k$
                    \subitem - with array implementation, \code{find(k)} $\in O(n)$ where $n = |X|$
                \item \code{find\_min()} - returns item with smallest key
                \item \code{find\_max()} - returns item with largest key
                \item \code{find\_next(k)} - return next smallest item from $k$ (?)
                \item \code{find\_prev(k)} - return next largest item from $k$ (?)
                \item with array, min, max, prev, next all $\in O(n)$
    
            \end{enumerate}
        \subsubsection{Dynamic Operations}
            \begin{enumerate}
                \item \code{insert\_at(x, i)} - insert element $x$ at index $i$
                \item \code{delete\_at(i)} - delete and return element at $i$
                \item with array, insert/delete $\in O(n)$
            \end{enumerate}
        \subsubsection{Running times}
            \begin{enumerate}
                \item with sorted array, $\code{find(k)}, \code{prev}, \code{next} \in O(\log n)$, insert/delete in n, find min/max in 1, build is nlogn
            \end{enumerate}


    \subsection{Direct access table}
        \subsubsection{Example}
        \begin{enumerate}
            \item items are Reed students
            \item ``keyspace'' is all possible 8-digit ID numbers
            \item index by Reed ID makes $\code{find(k)} \in O(1)$, but wastes space
        \end{enumerate}

    \subsection{Hash tables}
Before: sorting and searching using only comparisons on items.\\
Now: use keys in more complex ways arrow direct access table\\

\begin{verbatim}
    h : {ids} -> {0, ... , m-1}
    # assume m = Theta(m)
\end{verbatim}
store items as determined by h(key)\\
cannot be a bijection\\
collision: things in ids that map to same idem in codomain\\
solution: instead of storing item in table, store pointer to another data structure\\
``Chaining'' to some other data structure\\
\begin{verbatim}
    def hash.find(k):
    digest = h(k)
    c = get(h.direst) -> go find k?
\end{verbatim}
\subsubsection{Running time }
ideally: all chains are constant size so then all operations on chains are constant size\\
\\
chose m,h such that all chains end up with about n/m approx O(1) things in them\\
\subsubsection{Example}
modular division: \verb|h(k) = k mod(m)|.\\
Problem: only as even as keys themselves\\
if too even, might get mapped to same thing\\
\subsubsection{Better example: universal family of hash functions}
example of one family:\\
defien $h_{ab}(k) = (((ak +b)\mod p)\mod m)$ where $p$ is a large prime and 
$a,b$ chosen randomly from 0 to p-1\\
Formally, define family $\cH(p, m) = \{h_{ab}(k) ~|~ a, b \in [0 \dots p-1] \text{ and } a \neq 0 \}$
desired property: for some $h \in \cH$, Pr that any pairs of keys collide [$h(k_1)= h(k_2)$] $\leq \frac{1}{m}$ for all k1, k2 such that k1 not equal k2 
\\
parallel concept for sorting comparison model\\
lower bound Omega (n log n)
\subsection{Binary Trees}
traversal order: flatten tree
\textbf{Operations: }
\begin{enumerate}
    \item \code{find\_first()}: finds the first node in traversal order. go left until you can't anymore
    \item \code{find\_last()}: finds last node in traversal order. goes right until you can't anymore 
\end{enumerate}
\section{Running Time}
\subsection{red black}
root black\\
every leaf black\\
if node is red, both children are black\\
for every node, all paths from node to each descendant have same number of black nodes



\section{Correctness proof}
\subsection{Loop invariant method}
\textbf{Sketch: }
\begin{enumerate}
    \item Define a loop invariant $L$
    \item \textbf{Initialization: }prove $L$ holds before 1st iteration
    \item \textbf{Maintenance: }if $L$ holds before loop, still true before next one
    \item \textbf{Termination: }show that loop terminates and that $L$ still holds
\end{enumerate}





\section{Recursion}
running time for recursive algo
"solving a recurrance"
- substitution method
- recurrence tree
- master theorem
\section{Limits}
\subsection{Limit Laws}

% L’Hospital’s Rule
% suppose:
% \[ \lim_{x\to\a} f(x)/g(x) = 0/0 \] or \[ \lim_{x\to\a} f(x)/g(x) = frac{+- infinity}{+- infinity} \]
% where 
% a
%  can be any real number, infinity or negative infinity. In these cases we have,
%  \lim_{x\to\a} f(x)/g(x) =\lim_{x\to\a} f(x)'/g(x)' =

\section{Sorting}

\begin{tabular}{|c||c|c|c|}
    \hline
    \textbf{Sorting Algorithm} & \textbf{Best Case} & \textbf{Average Case} & \textbf{Worst Case} \\
    \hline
    \textbf{Bubble Sort} & $O(n)$ & $O(n^2)$ & $O(n^2)$ \\
    \textbf{Selection Sort} & $O(n^2)$ & $O(n^2)$ & $O(n^2)$ \\
    \textbf{Insertion Sort} & $O(n)$ & $O(n^2)$ & $O(n^2)$ \\
    \textbf{Merge Sort} & $O(n \log n)$ & $O(n \log n)$ & $O(n \log n)$ \\
    \textbf{Quick Sort} & $O(n \log n)$ & $O(n \log n)$ & $O(n^2)$ \\
    \textbf{Heap Sort} & $O(n \log n)$ & $O(n \log n)$ & $O(n \log n)$ \\
    % \textbf{Counting Sort} & $O(n + k)$ & $O(n + k)$ & $O(n + k)$ \\
    % \textbf{Radix Sort} & $O(nk)$ & $O(nk)$ & $O(nk)$ \\
    \hline
    \end{tabular}

\subsection{Permutation Sort}
    \begin{verbatim}
        permutation_sort(A):
            generate every possible permutation of A
            check if A is sorted
            continue until you find a sorted permutation
    \end{verbatim}

\subsection{Selection Sort}
    \begin{verbatim}
        selection_sort(A, i):
            1. finds biggest item in A[:i]
            2. swaps biggest thing with thing at A[i]
            3. recurse on A[:i-1]
    \end{verbatim}

\subsection{Merge Sort}
\begin{verbatim}
    if n = 0, 1: done
    otherwise:
        split array into Left, Right
        MergeSort(Left), MergeSort(Right)
        Merge(Left, Right)
\end{verbatim}
\begin{enumerate}
    \item specificity: array A, p starting point, r ending point
    \item if p geq r (if p equal to r, then only one element and return)
    \item convention: A[a:b] = [] if b less than A
    \item a:b means including both end points
    \item define midpoint $q = (p+r)/2$ (floor of the averge)
    \item Left = A[p:q]
    \item Right A[q+1:r]
    \item MergeSort(A, p, q)
    \item MergeSort(A, q+1, r)
    \item Merge(A, p, q, r)
\end{enumerate}
\begin{enumerate}

\item comparisons in constant time? \begin{enumerate}
    \item mostly comparing integers
    \item assume $i \leq j$ in constant time
    \item might be more complex
    \item    
\end{enumerate}
\end{enumerate}


\section{Binary Search Trees}
O(h) time where h is height\\
usually use these for sets\\
example: set us cs profs\\
name/id\\
adam/560\\
charlie/703\\
erica/998\\
greg/997\\
jim/100\\
include bst from notes\\
properties: for any X, keys in x.left leq x.key leq keys x.right\\
can also store a sequence in this way\\
ex 2: grocery list\\
apples, bananas, cereal, dish soap, eggs\\
order doesn't matter\\
bst property: for any L[i], all items in L[i].left appear before L[i]\\
all items in right subtree appear after L[i]
is balanced, height is at most O(log n)\\
when balanced, called red-black trees\\
\\
\\
\subsection{non-modifying operations}
\begin{enumerate}
    \item find min - all the down left
    \item find max - all the way down right 
    \item kind k - compare at every node
    \item 
\end{enumerate}
\subsection{modifying properties}
\begin{enumerate}
    \item insert item: traverse, then insert as a leaf
    \item delete: find successor and swap 16 with 17, then remove old leaf (find a safe leaf to remove)
    \item 
\end{enumerate}
balanced if even under dynamic operations it maintains height O log N\\
red-black tree\\
\begin{enumerate}
    \item dummy nodes
    \item imagine single dummy node "tree ends"
    \item stop drawing them
\end{enumerate}
loop invariants\\
different cases for red black trees\\
\section{priority queues and heaps}
\subsection{Priority Queue Interface}
new: delete max - remove item with highest priority\\
find max = find highest priority item\\
supports subset of set interface operations\\
optemized for finding min or max, we will focus on max priority\\
also has insert and build
\subsection{priority queue sort}
algo in slides\\
simple because you make the ds do it\\
\subsection{binary heaps}
\subsubsection{infer tree from aray}
require: completely full in upper levels (until last level)\\
binary trees with n things -> arrays of length n\\
bottom level should be left justified\\
diferent than traversal ordering function\\
root is index 0\\
finding the left child of i is just at index 2i+1\\
right(i) = 2i+2\\
parent(i) = floor((i-1)/2)\\
max heap properties:
\begin{enumerate}
    \item at node l, the value of thing at position l is going to be at least the value its children\\
    \item 
\end{enumerate}
tree does not live in memory, just array\\
we want higher importance nodes to be closer to the top\\
bottom layer is less than all elements above it\\
example 1 from slides: not a max heap: 15 is a node that is is not greater than or equal to both of its children\\
\\
inserting(x)\\
-append x to array: whole function is in O(logn)\\
-fix problems in heap\\
fixing: swap up with parents until max heap rule is followed:\\
check that val of parent geq val node, if no, swap and keep going\\
delete-max():\\
this deletes the root! \\
1. swap root with item at node number n-1, then delete thing at n-1\\
the fix downwards:\\
- start at root\\
- swap it with the greater key in its children, then continue\\
this is o of log n time
\section{Cheat Sheets}


% % \begin{table}[h]
% %     \small
% %     \begin{tabular}{l ||| ccccc|||}
    
% %     \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Sequence\\ Data Structure\end{tabular}} &
% %     \multicolumn{5}{c|||}{Operations $O(\cdot)$} \\ \cline{2-6}
% %       & \multicolumn{1}{c||}{Container}  
% %       & \multicolumn{1}{c||}{Static} 
% %       & \multicolumn{3}{c|||}{Dynamic}  \\ \cline{2-6} 
% %       & \multicolumn{1}{c||}{\footnotesize${\mathtt{build(X)}}$} 
% %       & \multicolumn{1}{c||}{\footnotesize\begin{tabular}[c] {@{}c@{}}${\mathtt{get\_at(i)}}$\\ ${\mathtt{set\_at(i,x)}}$\end{tabular}}
% %       & \multicolumn{1}{c|}{\footnotesize\begin{tabular}[c]{@{}c@{}}${\mathtt{insert\_first(x)}}$\\ ${\mathtt{delete\_first()}}$\end{tabular}}
% %       & \multicolumn{1}{c|}{\footnotesize\begin{tabular}[c]{@{}c@{}}${\mathtt{insert\_last(x)}}$\\ ${\mathtt{delete\_last()}}$\end{tabular}} &
% %       \footnotesize\begin{tabular}[c|]{@{}c@{}}${\mathtt{insert\_at(i,x)}}$\\ ${\mathtt{delete\_at(i)}}$\end{tabular} \\ \hline
      
%     % Array   & \multicolumn{1}{c||}{\nTable{}} & \multicolumn{1}{c||}{\constTable{}} & \multicolumn{1}{c|}{\nTable{}}   & \multicolumn{1}{c|}{\nTable{}}     &  \multicolumn{1}{c|||}{\nTable{}}       \\ \hline
%     % Linked List	 & \multicolumn{1}{c||}{\nTable{}}	 & \multicolumn{1}{c||}{\nTable{}} 	& \multicolumn{1}{c|}{\constTable{}} & \multicolumn{1}{c|}{\nTable{}}   & \multicolumn{1}{c|||}{\nTable{}}    \\ \hline
%     % Dynamic Array  & \multicolumn{1}{c||}{\nTable{}}  & \multicolumn{1}{c||}{\constTable{}}  & \multicolumn{1}{c|}{\nTable{}}  & \multicolumn{1}{c|}{\customCell{\bestcolor}{$1_{(a)}$}}    &  \multicolumn{1}{c|||}{\nTable{}}    \\ \hline
%     % Binary Tree  & \multicolumn{1}{c||}{\nlognTable{}}  & \multicolumn{1}{c||}{\hTable}  & \multicolumn{1}{c|}{\hTable{}}  & \multicolumn{1}{c|}{\hTable{}}    &  \multicolumn{1}{c|||}{\hTable{}}    \\ \hline
%     % \end{tabular}
%     % \end{table}
    
    
    % \begin{table}[h]
    % \normalsize
    % \begin{tabular}{l ||| ccccc|||}
    
    % \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Set\\ Data Structure\end{tabular}} &
    % \multicolumn{5}{c|||}{Operations $O(\cdot)$} \\ \cline{2-6}
    %   & \multicolumn{1}{c||}{Container}  
    %   & \multicolumn{1}{c||}{Static} 
    %   & \multicolumn{1}{c||}{Dynamic}  
    %   & \multicolumn{2}{c|||}{Order}  \\ \cline{2-6} 
    %   & \multicolumn{1}{c||}{\footnotesize${\mathtt{build(X)}}$} 
    %   & \multicolumn{1}{c||}{\footnotesize${\mathtt{find(k)}}$}
    %   & \multicolumn{1}{c||}{\footnotesize\begin{tabular}[c]{@{}c@{}}${\mathtt{insert(x)}}$\\ ${\mathtt{delete(k)}}$\end{tabular}}
    %   & \multicolumn{1}{c|}{\footnotesize\begin{tabular}[c]{@{}c@{}}${\mathtt{find\_min()}}$\\ ${\mathtt{find\_max()}}$\end{tabular}} &
    %   \footnotesize\begin{tabular}[c|]{@{}c@{}}${\mathtt{find\_prev(k)}}$\\ ${\mathtt{find\_next(k)}}$\end{tabular} \\ \hline 
      
    % Array   & \multicolumn{1}{c||}{\nTable{}} & \multicolumn{1}{c||}{\nTable{}} & \multicolumn{1}{c||}{\nTable{}}   & \multicolumn{1}{c|}{\nTable{}}     &  \multicolumn{1}{c|||}{\nTable{}}       \\ \hline
    % Sorted Array	 & \multicolumn{1}{c||}{\nlognTable{}}	 & \multicolumn{1}{c||}{\lognTable{}} 	& \multicolumn{1}{c||}{\nTable{}} & \multicolumn{1}{c|}{\constTable{}}   & \multicolumn{1}{c|||}{\lognTable{}}    \\ \hline
    % Direct Access Array  & \multicolumn{1}{c||}{\uTable{}}  & \multicolumn{1}{c||}{\constTable{}}  & \multicolumn{1}{c||}{\constTable{}}  & \multicolumn{1}{c|}{\uTable{}}    &  \multicolumn{1}{c|||}{\uTable{}}    \\ \hline
    % Hash Table      & \multicolumn{1}{c||}{\customCell{\badcolor}{$n_{(e)}$}}  & \multicolumn{1}{c||}{\customCell{\bestcolor}{$1_{(e)}$}}                         & \multicolumn{1}{c||}{\customCell{\bestcolor}{$1_{(a)(e)}$}}  & \multicolumn{1}{c|}{\nTable{}}   &   \multicolumn{1}{c|||}{\nTable{}}                                                                                    \\ \hline
    % Binary Tree      & \multicolumn{1}{c||}{\nTable{}}  & \multicolumn{1}{c||}{\hTable{}}  & \multicolumn{1}{c||}{\hTable{}}  & \multicolumn{1}{c|}{\hTable{}}   &   \multicolumn{1}{c|||}{\hTable{}}                                                                                    \\ \hline
    % \end{tabular}
    % \end{table}
    




\subsection{Running Times for DS}
\begin{center}
    

\begin{tabular}{ |p{3cm}||p{3cm}|p{3cm}|p{3cm}|p{3cm}|  }
    \hline
    \multicolumn{5}{|c|}{Operations $O(\cdot)$} \\
    \hline
    Set Data Structure& Container& Static& Dynamic& Order\\
    \hline
    array&   AX  & ALA   &248\\
    sorted array&AL & ALB&  008\\

    \hline
   \end{tabular}
\end{center}
\subsection{orders}


\section{servers}
\begin{enumerate}
    \item servers and clients
    \item each server: some capacity
    \item each client: some workload
    \item assign so that no server goes over its capacity
\end{enumerate}
implementation
\begin{enumerate}
    \item initialize(X) whre X is set of servers
    \item connect(client, workload)
    \item disconnect(client)
    \item clients-of(server): return list of clients connected to that server
\end{enumerate}
how to do:\\
idea\\
use priority queue for clients and prioritize biggest \\
priority queue for servers so that you can find best fit the best\\
\\
notes on actual:\\
server has set of clients where key is client id and value is workload\\
priority queue storing the servers\\
store based on priorty, which is available capacity\\
\\
structures:\\
pq P:(server.id, available capacity)\\
set S: (maps server id to set of clients and pointer to si in P)
set C: maps client id to connected server and workload (if not stored as client object)

\section{Graph algorithms}
    \subsection{Definition}
        \begin{enumerate}
            \item $G = (V, E)$ where for all $(u,v) \in E, $ $u \neq v$ and no duplicate edges (for this class)
            \item $Adj+(u) := \{v \in V ~|~ (u, v) \in E\}$ (outgoing neighbors of node $u$)
            \item incoming neighbord of u Adj - (u) = set(v in V st (v, u) in E)
            \item out degree(u) = size of adj+
            \item in degree(u) = size adj -\\
        \end{enumerate}
    \subsection{Representing graphs}
    matrix or adj list\\
    storing:\\
    top level set adj of vertices\\
    lower level: adj lists Adj(u) either set or sequence (default to outgoing\\
    can be direct access array\\
    )
    \subsection{Running time}
        \begin{enumerate}
            \item linear means O(V + E) (size of those sets)
            \subitem doing something with each edge and each vertex
            \item $|E| = O(V^2)$ for simple graphs
            \subitem most edges you can have is fully connected graph
            \item undirected: |E| leq size of V choose 2 (proved on homework)
            \item directed : |E| leq 2 times (V size chose 2)
        \end{enumerate}



\subsection{Breadth-first search}


\subsection{Path problems}



\section{Rules}
\subsection{Sum rules}
\subsection{Log rules}
\begin{tabular}{|c|c|}
    \hline
    Product rule & $\log_b(MN)=\log_b(M)+\log_b(N)$ \\
    \hline
    Quotient rule & $\log_b\left(\dfrac{M}{N}\right)=\log_b(M)-\log_b(N)$ \\
    \hline Power rule & $\log_b(M^p)=p\cdot\log_b(M)$\\
    \hline Base switch rule & $\log_b(c)=\frac{1}{\log_c(b)}$\\
    \hline Base change rule & $\log_b(x)=\frac{\log_c(x)}{\log_c(b)}$\\
    \hline
    \end{tabular}


\section{Midterm review}


\section{Lecture 16}
\subsection{Topological Sort}
"finishing order" - order in which is finishes visiting (recursive calls pop all the way up)\\
DAG meaning?\\
\begin{definition}
    Topological order of $G = (V, E):$ ordering of vertices such that every (u, v) in E satisfies that u is before v in the order (in context of directed graphs)
\end{definition}
Find topological ordering of graph:
Edges = (A,C)
(C, E)
(A, B)
(B, G)
(B, E)
(C, D)
(E, D)
(E, F)

check: ACBEDFG

other: ABGCEDF

order for F and G don't matter

Story problem: teams

Solution sketch:
\begin{enumerate}
    \item Given info, what is the graph? vertices = set of employees, edges are links
    \item goal: a topological ordering satisfies the constraint
    \item find topological ordering or prove none exists
    \item prove none exists: get sequence, check if topological
    \item (reverse of visiting order is a topological sort)
    \item solution exists iff G is a DAG 
    \item alternatively show a cycle so there is no ordering
    \item or show graph is acyclic -> topological ordering exists
\end{enumerate}
can solve by cycle detection problem
% Given: list of employees and information about how employees are linked

% stratify in levels, break ties somehow

% doesn't work if there is a cycle in the graph

% must be someone with no incoming edges 


\subsection{Weighted Graphs}
unweighted: distance is num edges in shortest paths\\
add a weight function from set of edges to integers\\
\subsection{weighted paths terminology}
why infinum? has to do with range of weights we're trying to consider

problem with negative weghts and cycles\\
confused...

get nice graph


\section{Lecture 17}
assume G is (undirected) graph satisfies def 1 (show that G must also satisfy def 2)


weighted graphs
given shortest paths weights, can compute shortest paths tree in linear time (O(V + E))



\subsection{DAG Relaxation}
high level: 

for each vertex, maintain estimate which is upper bound as true shortest distance distance

repeatedly improve

refining estimates: true shortest-path weight between any pair of vertices u, v is upper bounded by 
weight of shortest path from u to v that has a specific last edge (x, v)

proposing path through x as possible path


see slide for formal definition

update estimate to use edge if edge exists to make it shorter



\subsection{Bellman-Ford}



\section{Logical Equivalence}


\begin{tabular}{|c|c|c|}
    \hline
    Contrapositive & $P \implies Q$ & $!Q \implies !P$ \\
    \hline

\end{tabular}




% \section{Feedback}
% \subsection{Problem set 1}
% \begin{enumerate}
%     \item Missing justification of $n \leq (log n)^(log n)$
%     \item Give a specific expression for the new $n_0, c_1, c_2$ in 
%     terms of the corresponding constants for f and g. 
%     Also, note that the definition of f(n) in O(g) (or Theta(g), 
%     or Omega(g)) only tells us that there exist constants such that 
%     the inequality holds, not necessarily equality. So in the case of O(g), 
%     we know there exist c, $n_0$ s.t. $0<=f(n)<=c g(n)$ for all $n>=n_0$, 
%     but it is not necessarily true that there exists c, $n_0$ s.t. $f(n)=c g(n)$ 
%     for all $n>=n_0 (<= vs =)$.
% \end{enumerate}
% \subsection{Problem set 2}
% \subsection{Problem set 3c}






% % \subsection{Citation}

% % This is a citation\cite{Eg}.

% % \newpage

% % % ------------------------------------------------------------------------------
% % % Reference and Cited Works
% % % ------------------------------------------------------------------------------

% % \bibliographystyle{IEEEtran}
% % \bibliography{References.bib}

% % % ------------------------------------------------------------------------------





\end{document}
